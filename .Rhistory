filter(is.na(age)) |>
as_Spatial() ->
present
wcape_wards |>
filter(!is.na(age)) |>
as_Spatial() ->
missing
wcape_wards |>
filter(!is.na(age)) |>
as_Spatial() ->
present
wcape_wards |>
filter(is.na(age)) |>
as_Spatial() ->
missing
plot(present)
plot(missing, col = 'red', add = T)
# Interploation
bw <- bw.gwr(age ~ 1, data = present,
adaptive = TRUE, kernel = "bisquare", longlat = T,
approach = "AIC")
gwstats <- gwss(present, missing, vars = "age", bw = bw, kernel = "bisquare",
adaptive = TRUE, longlat = T)
mch <- match(missing$WardID, wcape_wards$WardID)
wcape_wards$age[mch] <- gwstats$SDF$age_LM
bw <- bw.gwr(No_schooling ~ 1, data = present,
adaptive = TRUE, kernel = "bisquare", longlat = T, approach = "AIC")
gwstats <- gwss(present, missing, vars = "No_schooling", bw = bw, kernel = "bisquare",
adaptive = TRUE, longlat = T)
wcape_wards$No_schooling[mch] <- gwstats$SDF$No_schooling_LM
# retain interpolated tags
wcape_wards$interpolated <- F
wcape_wards$interpolated[mch] <- T
# check
table(wcape_wards$interpolated)
# ols
ols2 <- update(ols1, .~., + interpolated*age)
summary(ols2)
summarY(OLS1)
summary(ols1)
if(!("remotes" %in% installed.packages()[,1])) install.packages("remotes", dependencies = TRUE)
if(!("ggsflabel" %in% installed.packages()[,1])) remotes::install_github("yutannihilation/ggsflabel")
require(sf)
require(tidyverse)
require(ggplot2)
require(ggsflabel)
if(!file.exists("covid.geojson")) download.file("https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/covid.geojson",
"covid.geojson", mode = "wb", quiet = TRUE)
read_sf("covid.geojson") |>
filter(regionName == "North West") ->
covid
covid |>
filter(Rate > 400) |>
select(LtlaName) |>   # LtlaName is the name of the local authority
filter(!duplicated(LtlaName)) ->
high_rate
ggplot() +
geom_sf(data = covid, aes(fill = Rate), size = 0.25) +
scale_fill_distiller(palette = "YlOrRd", direction = 1) +
geom_sf_label_repel(data = high_rate, aes(label = LtlaName), size = 3,
alpha = 0.5) +
theme_void()
# Moran test
require(spdep)
spweight <- nb2listw(poly2nb(covid, snap = 1))
moran.test(covid$Rate, spweight)
# Correlation
cor(lag.listw(spweight, covid$Rate), covid$Rate)
require(GWmodel)
covid_sp <- as_Spatial(covid)
bw <- bw.gwr(Rate ~ 1, data = covid_sp,
adaptive = TRUE, kernel = "bisquare", longlat = F)
gwstats <- gwss(covid_sp, vars = "Rate", bw = bw, kernel = "bisquare",
adaptive = TRUE, longlat = F)
# Plot model
covid$Rate_LM <- gwstats$SDF$Rate_LM
ggplot(covid, aes(fill = Rate_LM)) +
geom_sf(size = 0.25) +
scale_fill_distiller(palette = "YlOrRd", direction = 1) +
theme_void()
coords <- st_centroid(covid, of_largest_polygon = TRUE)
neighbours <- dnearneigh(coords, 0, 5000)
spweightB <- nb2listw(neighbours, style = "B", zero.policy = TRUE)
covid$localG <- localG(covid$Rate, spweightB)
brks <- c(min(covid$localG, na.rm = TRUE),
-3.29, -2.58, -1.96, 1.96, 2.58, 3.29,
max(covid$localG, na.rm = TRUE))
covid$localG_gp <- cut(covid$localG, brks, include.lowest = TRUE)
pal <- c("purple", "dark blue", "light blue", "light grey",
"yellow", "orange", "red")
ggplot(covid, aes(fill = localG_gp)) +
geom_sf(size = 0.25) +
scale_fill_manual("G", values = pal, na.value = "white",
na.translate = F) +
theme_void() +
guides(fill = guide_legend(reverse = TRUE))
ols1 <- lm(Rate ~ IMD + age0.11 + age12.17 + age18.24 + age25.34 + age35.39 +
age50.59 + age60.69 + age70plus + density +
carebeds + AandE, data = covid)
summary(ols1)
pal <- c("purple", "dark blue", "light blue", "light grey",
"yellow", "orange", "red")
pal <- c("purple", "dark blue", "light blue", "light grey",
"yellow", "orange", "red") +
ggplot(covid, aes(fill = localG_gp)) +
geom_sf(size = 0.25) +
scale_fill_manual("G", values = pal, na.value = "white",
na.translate = F) +
theme_void() +
guides(fill = guide_legend(reverse = TRUE))
# Multi linear regression
ols1 <- lm(Rate ~ IMD + age0.11 + age12.17 + age18.24 + age25.34 + age35.39 +
age50.59 + age60.69 + age70plus + density +
carebeds + AandE, data = covid)
summary(ols1)
# Plot Regresion results
par(mfrow = c(2,2))
plot(ols1)
if(!("car" %in% installed.packages()[,1])) install.packages("car")
require(car)
# #
vif(ols1)
# Show summary
summary(ols1)
# Install required libraries
install.packages("sp", "gstat")
# Install required libraries
install.packages("sp", "gstat")
# Load required libraries
library(sp)
library(gstat)
# Load obs data
read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940.csv")
# Load obs data
dat -> read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940.csv")
# Load obs data
dat <- read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940.csv")
years <- unique(dat$Year)
# Load obs data
dat <- read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940_R.csv")
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = subset_data["Value"])
})
subset_data <- subset(data, data$Year == year)
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = data.frame(Value = subset_data$Value))
})
# Load obs data
data <- read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940_R.csv")
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = data.frame(Value = subset_data$Value))
})
# Set years
years <- unique(data$Year)
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = data.frame(Value = subset_data$Value))
})
# An example of defining a model (you may need to modify this according to your data):
variogram_model <- vgm(psill = 1, model = "Sph", range = 1000, nugget = 0.1)
# Perform Bayesian Kriging for each year and store the results in a list
results_list <- lapply(spatial_data_list, function(spatial_data) {
krige.bayes(formula = Value ~ 1, locations = spatial_data, model = variogram_model, nsim = 100)
})
library(gstat)
# Perform Bayesian Kriging for each year and store the results in a list
results_list <- lapply(spatial_data_list, function(spatial_data) {
krige.bayes(formula = Value ~ 1, locations = spatial_data, model = variogram_model, nsim = 100)
})
# Install required libraries
install.packages("sp", "gstat", "geoR")
install.packages("sp", "gstat", "geoR")
install.packages("sp", "gstat", "geoR")
library(geoR)
# Install required libraries
install.packages("geoR")
library(geoR)
# Load required libraries
library(sp)
library(gstat)
# Load obs data
data <- read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940_R.csv")
# Set years
years <- unique(data$Year)
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = data.frame(Value = subset_data$Value))
})
# An example of defining a model (you may need to modify this according to your data):
variogram_model <- vgm(psill = 1, model = "Sph", range = 1000, nugget = 0.1)
# Perform Bayesian Kriging for each year and store the results in a list
results_list <- lapply(spatial_data_list, function(spatial_data) {
krige.bayes(formula = Value ~ 1, locations = spatial_data, model = variogram_model, nsim = 100)
})
krige.bayes(locations = spatial_data, model = variogram_model)
spatial_data_list
# build empirical var
var <- gstat::variogram(object = data, locations = spatital_data_list)
# build empirical var
var <- gstat::variogram(object = data, locations = spatial_data_list)
# build empirical var
var <- gstat::variogram(object = data, locations = spatial_data_list$coords)
# Load required libraries
library(sp)
library(gstat)
library(geoR)
## Kriging
# Load obs data
data <- read.csv("/Users/benjaminmellor/GEOGM00XX_DISS/cnn/data/obs_ts_1940_R.csv")
# Set years
years <- unique(data$Year)
# Create a SPDF for each year
spatial_data_list <- lapply(years, function(year) {
subset_data <- subset(data, Year == year)
coordinates(subset_data) <- c("Longitude", "Latitude")
SpatialPointsDataFrame(subset_data, data = data.frame(Value = subset_data$Value))
})
?gstat::variogram
# Create variogram
var <- gstat::variogram(object = data-1,
locations = spatial_data_list
)
var_list <- lapply(spatial_data_list, function(build_variogram){
gstat::variogram(object = Value~1,
locations = spatial_data_list)
})
gstat::variogram(object = Value~1,
data = spatial_data_list,
locations = spatial_data_list)
gstat::variogram(object = spatial_data_list$Value~1,
data = spatial_data_list,
locations = spatial_data_list)
gstat::variogram(object = spatial_data_list$data$Value~1,
data = spatial_data_list,
locations = spatial_data_list)
getwd()
setwd('/Volumes/BENSTON/github_repos/MRP_2019Gen')
rm(list=ls(all=TRUE))
## ----loadlibs-------------------------------------------------------------
library("haven")
library("arm")
library("foreign")
library("lme4")
library("survey")
library("dplyr")
library("rstanarm")
library("ggplot2")
library("bayesplot")
library("parallel")
library("tidyverse")
library("mlogit")
theme_set(bayesplot::theme_default())
# read in
census_data <- read.csv("Data/ONS.csv")
census_data <- census_data %>%
dplyr::select(GSSCode, SexCode, AgeCode, EduCode, Observation)
# weight
ukpop <- sum(census_data$Observation)
census_data$weight <- census_data$Observation / ukpop
Sample <- read_dta("Data/bes_w18_2019.dta")
Sample <- Sample %>%
dplyr::select(
generalElectionVote, gender, age, ageGroup, pcon_code, p_edlevel
) %>%
rename(
Vote = generalElectionVote,
GSSCode = pcon_code,
Age = age,
Sex = gender,
EdLevel = p_edlevel
)
# Set up for ONS Congruency
age_breaks <- c(-Inf, 15, 24, 34, 49, 64, Inf)
age_labels <- c("0-15",
"16-24",
"25-34",
"35-49",
"50-64",
"65+")
Sample$AgeQ <- as.numeric(
as.character(Sample$Age)
)
Sample$AgeCode <- cut(
Sample$AgeQ,
breaks = age_breaks,
labels = age_labels
)
SampleComplete <- Sample[complete.cases(Sample),]
table(SampleComplete)
table(SampleComplete$GSSCode)
# 1.  Multi Level Regression
fit1 <- stan_glmer(
Vote ~
AgeCode + EdLevel + Sex + (1|GSSCode),
data = SampleComplete,
family = stats::gaussian()
)
summary(fit1)
mse <- rstanarm::predictive_error(fit1, draws = 100) ^ 2
## ----loadlibs-------------------------------------------------------------
library("haven")
mse <- rstanarm::predictive_error(fit1, draws = 100) ^ 2
iters <- fit1$stanfit@stan_args[[1]]$iter
View(Sample)
# read in
BES_rps <- read_dta("Data/bes_rps_2019.dta")
BES_rps <- BES_rps %>%
dplyr::select(Constit_Code, b01, Q24_CSES, y09, edlevel)
BES_rps <- BES_rps %>%
rename(
GSSCode = Constit_Code,
VoterTurnout = b01,
Age = Q24_CSES,
Sex = y09,
EdLevel = edlevel
)
## Sex
# clean for agreement with ONS
BES_rps <- BES_rps %>%
dplyr::filter(Sex %in% c(1, 2))
## Age
# categorise and clean for agreement with ONS
BES_rps$AgeQ <- as.numeric(
as.character(BES_rps$Age)
)
BES_rps$AgeCats <- cut(
BES_rps$AgeQ,
breaks = age_breaks,
labels = age_labels
)
BES_rps$AgeCode <- as.factor(
dplyr::recode(BES_rps$AgeCats,
"1" = "0-16",
"2" = "16-24",
"3" = "25-34",
"4" = "35-49",
"5" = "50-64",
"6" =   "65+")
)
# read in
BES_rps <- read_dta("Data/bes_rps_2019.dta")
BES_rps <- BES_rps %>%
dplyr::select(Constit_Code, b01, Q24_CSES, y09, edlevel) %>%
rename(
GSSCode = Constit_Code,
VoterTurnout = b01,
Age = Q24_CSES,
Sex = y09,
EdLevel = edlevel
) %>%
dplyr::filter(Sex %in% c(1, 2)) %>%
dplyr::filter(VoterTurnout %in% c(1, 2))
BES_rps$AgeQ <- as.numeric(
as.character(BES_rps$Age)
)
BES_rps$AgeCats <- cut(
BES_rps$AgeQ,
breaks = age_breaks,
labels = age_labels
)
BES_rps$AgeCode <- as.factor(
dplyr::recode(BES_rps$AgeCats,
"1" = "0-16",
"2" = "16-24",
"3" = "25-34",
"4" = "35-49",
"5" = "50-64",
"6" =   "65+")
)
# Estimate based on demographics
turnfit <- stan_glmer(
VoterTurnout ~
AgeCode + EdLevel + Sex + (1|GSSCode),
data = BES_rps,
family = stats::gaussian()
)
## ----TurnoutRates----------------------------------------------------------
# Summarise the rate
turnout_summary <- BES_rps %>%
dplyr::group_by(GSSCode, Sex, AgeCode, EdLevel) %>%
dplyr::summarize(TurnoutPercentage = sum(VoterTurnout == 1, na.rm = TRUE) / n() * 100)
merged_data <- left_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
## ----loadONS--------------------------------------------------------------
# read in
census_data <- read.csv("Data/ONS.csv")
census_data <- census_data %>%
dplyr::select(
GSSCode, SexCode, AgeCode, EduCode, Observation
) %>%
rename(
Sex = SexCode,
EdLevel = EduCode
)
merged_data <- left_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
## ----TurnoutRates----------------------------------------------------------
# Summarise the rate
turnout_summary <- BES_rps %>%
dplyr::group_by(GSSCode, Sex, AgeCode, EdLevel) %>%
dplyr::summarize(TurnoutPercentage = sum(VoterTurnout == 1, na.rm = TRUE) / n() * 100) %>%
mutate(AgeCode = as.factor((AgeCode)))
merged_data <- left_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
BES_rps <- read_dta("Data/bes_rps_2019.dta")
BES_rps <- BES_rps %>%
dplyr::select(Constit_Code, b01, Q24_CSES, y09, edlevel) %>%
rename(
GSSCode = Constit_Code,
VoterTurnout = b01,
Age = Q24_CSES,
Sex = y09,
EdLevel = edlevel
) %>%
dplyr::filter(Sex %in% c(1, 2)) %>%
dplyr::filter(VoterTurnout %in% c(1, 2))
## Age
# categorise and clean for agreement with ONS
BES_rps$AgeQ <- as.numeric(
as.character(BES_rps$Age)
)
BES_rps$AgeCode <- cut(
BES_rps$AgeQ,
breaks = age_breaks,
labels = age_labels
)
BES_rps <- BES_rps %>%
select(-AgeQ, -Age)
SampleComplete <- Sample %>%
select(-ageGroup, -AgeQ) %>%
Sample[complete.cases(Sample),]
Sample <- Sample %>%
select(-ageGroup, -AgeQ)
Sample <- read_dta("Data/bes_w18_2019.dta")
Sample <- Sample %>%
dplyr::select(
generalElectionVote, gender, age, ageGroup, pcon_code, p_edlevel
) %>%
rename(
Vote = generalElectionVote,
GSSCode = pcon_code,
Age = age,
Sex = gender,
EdLevel = p_edlevel
)
# Set up for ONS Congruency
age_breaks <- c(-Inf, 15, 24, 34, 49, 64, Inf)
age_labels <- c("0-15",
"16-24",
"25-34",
"35-49",
"50-64",
"65+")
Sample$AgeQ <- as.numeric(
as.character(Sample$Age)
)
Sample$AgeCode <- cut(
Sample$AgeQ,
breaks = age_breaks,
labels = age_labels
)
Sample <- Sample %>%
select(-ageGroup, -AgeQ, -Age)
Sample <- Sample[complete.cases(Sample),]
View(SampleComplete)
View(SampleComplete)
merged_data <- left_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
# read in
census_data <- read.csv("Data/ONS.csv")
census_data <- census_data %>%
dplyr::select(
GSSCode, SexCode, AgeCode, EduCode, Observation
) %>%
rename(
Sex = SexCode,
EdLevel = EduCode
) %>%
mutate(AgeCode = as.factor(AgeCode))
# weight
ukpop <- sum(census_data$Observation)
census_data$weight <- census_data$Observation / ukpop
merged_data <- left_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
merged_data <- merged_data %>%
mutate(weighted_turnout = TurnoutPercentage * weight)
merged_data2 <- right_join(turnout_summary, census_data, by = c("GSSCode", "Sex", "AgeCode", "EdLevel"))
fit1
mse <- rstanarm::predictive_error(fit1, draws = 100) ^ 2
rlang::last_trace()
iters <- fit1$stanfit@stan_args[[1]]$iter
ps <- census_data
draws_ps <- rstanarm::posterior_epred(fit1,
draws = ifelse(iters > 500,
500,
iters),
newdata = ps)
# 1.  Multi Level Regression
fit <- stan_glmer(
Vote ~
AgeCode + EdLevel + Sex + (1|GSSCode),
data = Sample,
family = stats::gaussian()
)
